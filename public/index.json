
[{"content":"Hello! I\u0026rsquo;m Berry, an AI Engineer with over a decade of experience in Artificial Intelligence and Data Science. My passion lies in leveraging AI to help businesses become more efficient and competitive.\nWhat I Do # In my professional journey, I\u0026rsquo;ve had the opportunity to work on a variety of projects across diverse industries. Here are some of the key areas I specialize in:\nü§ñ AI and Automation Consulting: Helping businesses understand and integrate AI and automation solutions. üéì AI Training: Providing training sessions to help teams develop AI skills. üõ† AI Product Development: Building custom AI products from concept to deployment. üó£ Coaching: Offering one-on-one coaching to help professionals grow their AI expertise. Previous Experience # I\u0026rsquo;ve collaborated with a range of clients, delivering impactful AI and data solutions that drive business success:\nüèõ Dutch Government: Worked on setting up local LLMs and a scheduling mechanism for other teams to efficiently utilize our servers. üì° KPN: Created parsing logic in Python and Scala, and enhanced the monitoring system for Dutch railways using Prometheus and Grafana, resulting in improved operational efficiency. üìä VodafoneZiggo: Assisted in migrating data pipelines, ensuring a smooth transition and reliable data flow. üè¢ Mileway: Developed a document management system to automatically detect real estate documents, streamlining document handling and increasing accuracy. üè¶ Rabobank: Helped develop the data marketplace and set up data infrastructure, enabling better data management and accessibility. üõí Ahold: Created dashboards that provide insightful data visualizations, aiding in informed decision-making. üåç Unicef: Built an Azure data platform from scratch to enhance marketing efforts, significantly improving campaign effectiveness. üíº Van Lanschot Kempen: Developed solutions on the data lake architecture, facilitating better data storage and retrieval processes. Each project highlights my commitment to delivering tailored AI and data solutions that provide tangible benefits to my clients.\nCurrent Focus # My current focus is on scaling AI training programs to help more businesses become efficient using AI. By providing comprehensive training sessions and hands-on workshops, I aim to empower organizations to leverage AI technologies effectively.\nI am also working on a top-secret project for the Dutch government, pushing the boundaries of AI innovation. üé¨üïµÔ∏è‚Äç‚ôÇÔ∏è\nAcademic Journey # I hold a master\u0026rsquo;s degree in Data Science from the University of Amsterdam, where I conducted significant research in the field of AI. My research has been published on various platforms. One notable project was on domain adaptation in transformer models for question answering on Dutch government policies.\nDomain Adaptation in Transformer models: Question Answering of Dutch Government Policies üìö Let\u0026rsquo;s Connect # I‚Äôm always excited to connect with like-minded professionals and explore new opportunities. Whether you\u0026rsquo;re looking to implement AI solutions in your business or want to enhance your team\u0026rsquo;s AI capabilities, I\u0026rsquo;d love to help.\nYou can connect with me on the following platforms:\nüê¶ X üíº LinkedIn üíª GitHub ","date":"9 April 2024","externalUrl":null,"permalink":"/about/","section":"Berry Blom","summary":"Hello! I\u0026rsquo;m Berry, an AI Engineer with over a decade of experience in Artificial Intelligence and Data Science.","title":"About me","type":"page"},{"content":"","date":"9 April 2024","externalUrl":null,"permalink":"/","section":"Berry Blom","summary":"","title":"Berry Blom","type":"page"},{"content":" Intro # During my Master\u0026rsquo;s in Data Science at the University of Amsterdam, I worked on creating a Question Answering (QA) system for Dutch government policies using transformer models. This research aimed to improve how these models handle specific domains like government policies. In this blog post, I\u0026rsquo;ll share my approach, the new dataset we developed, and the key findings that enhanced the performance of our QA system.\nAcademic presentation # In November 2023, I presented my research at the University of Evora in Portugal. The audience consisted of academic researchers specializing in various AI fields, including computer vision, optimization, and other areas. I was part of the natural language processing group. Following this presentation, the research was published in collaboration with my UVA supervisor.\nI met many cool people during this event, with whom I am still in contact. This experience not only helped me share my work but also allowed me to network with other AI professionals.\nEvora, Portugal - November 24 2023\nAbstract # Automatic answering questions helps users in finding information efficiently, in contrast with web search engines that require keywords to be provided and large texts to be processed. The first Dutch Question Answering (QA) system uses basic natural language processing techniques based on text similarity between the question and the answer. After the introduction of pre-trained transformer-based models like BERT, higher scores were achieved with over 7.7% improvement for the General Language Understanding Evaluation (GLUE) score.\nPre-trained transformer-based models tend to over-generalize when applied to a specific domain, leading to less precise context-specific outputs. There is a marked research gap in experiment strategies to adapt these models effectively for domain-specific applications. Additionally, there is a lack of Dutch resources for automatic question answering, as the only existing dataset, Dutch SQuAD, is a translation of the SQuAD dataset in English.\nWe propose a new dataset, PolicyQA, containing questions and answers about Dutch government policies and use domain adaptation techniques to address the generalizability problem of transformer-based models.\nThe experimental setup includes the Long Short-Term memory (LSTM), a baseline neural network, and three BERT-based models, mBert, RobBERT, and BERTje, with domain adaptation. The datasets used for testing are the proposed PolicyQA dataset and the existing Dutch SQuAD.\nFrom the results, we found that the multilanguage BERT-model, mBert, outperforms the Dutch BERT-based models (RobBERT and BERTje) on the both datasets. By introducing fine-tuning, a domain adaptation technique, the mBert model improved to 94.10% of F1-score, a gain of 226% compared to its performance without fine-tuning.\nFull-text article # Read article\n","date":"4 August 2022","externalUrl":null,"permalink":"/projects/acetylcholinesterase/","section":"Projects","summary":"Intro # During my Master\u0026rsquo;s in Data Science at the University of Amsterdam, I worked on creating a Question Answering (QA) system for Dutch government policies using transformer models.","title":"Domain Adaptation in Transformer models: Question Answering of Dutch Government Policies","type":"projects"},{"content":"","date":"4 August 2022","externalUrl":null,"permalink":"/tags/first-post/","section":"Tags","summary":"","title":"First Post","type":"tags"},{"content":"","date":"4 August 2022","externalUrl":null,"permalink":"/tags/hello-world/","section":"Tags","summary":"","title":"Hello World","type":"tags"},{"content":"","date":"4 August 2022","externalUrl":null,"permalink":"/projects/","section":"Projects","summary":"","title":"Projects","type":"projects"},{"content":"","date":"4 August 2022","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":" Preview # The essential Streamlit for all your data science needs # To build a web app you‚Äôd typically use such Python web frameworks as Django and Flask. But the steep learning curve and the big time investment for implementing these apps present a major hurdle.\nStreamlit makes the app creation process as simple as writing Python scripts!\nIn this article, you‚Äôll learn how to master Streamlit when getting started with data science.\nLet‚Äôs dive in!\nRead blog\n","date":"8 April 2022","externalUrl":null,"permalink":"/posts/how-to-master-streamlit-for-data-science/","section":"Posts","summary":"Preview # The essential Streamlit for all your data science needs # To build a web app you‚Äôd typically use such Python web frameworks as Django and Flask.","title":"How to master Streamlit for Data Science","type":"posts"},{"content":"","date":"8 April 2022","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"15 February 2022","externalUrl":null,"permalink":"/tags/ai/","section":"Tags","summary":"","title":"AI","type":"tags"},{"content":" Enhancing Common Sense in Large Language Models: Insights from a Kaggle Competition # Endowing AI with common sense, the intuitive understanding of everyday situations, remains a significant hurdle. This challenge is crucial as it underpins the natural language understanding capabilities of AI, making interactions more human-like and reliable. Recently, I participated in a Kaggle competition aimed at evaluating and improving the common sense reasoning of natural language understanding systems. Here‚Äôs an overview of the competition, its importance, and my experience.\nThe Importance of Common Sense in AI # Introducing common sense to natural language understanding systems has garnered increasing attention within the research community. Unlike specific, domain-based knowledge, common sense involves a broad understanding of the world, enabling systems to handle ambiguous and context-dependent scenarios effectively. The ability to identify why a statement does not make sense is fundamental to building robust AI models capable of interacting with humans in a more intuitive and meaningful way.\nThe Challenge: Common Sense Reasoning # The competition posed a unique and intriguing task: Given a statement that defies common sense, can a model identify the best explanation for why it does not make sense? Participants were required to choose the most appropriate reason from three given options. For example:\nStatement: He put an elephant into the fridge.\nA: An elephant is much bigger than a fridge. (correct) B: Elephants are usually white while fridges are usually white. C: An elephant cannot eat a fridge. In this instance, option A is correct because it directly addresses the implausibility of the statement based on the relative sizes of an elephant and a fridge.\nEvaluation and Submission # The evaluation was straightforward yet challenging. Submissions were assessed based on category accuracy, which measures the proportion of correctly identified explanations:\n[ \\text{Category Accuracy} = \\frac{1}{N} \\sum_{i=1}^{N} (y_i = \\hat{y}_i) ]\nWhere ( N ) is the number of sentences in the test set, ( y_i ) is the true label, and ( \\hat{y}_i ) is the predicted label. Achieving a score around 0.33, akin to random guessing, was the baseline.\nParticipants were required to submit their predictions in a CSV format, containing the sentence IDs and the corresponding predicted labels. The dataset comprised 8000 sentences for training and 2000 sentences for testing.\nDataset and Files # The provided dataset included:\ntrain_data.csv: The training set with sentences and options. train_answers.csv: Correct labels for the training set. test_data.csv: The test set. sample.csv: A sample submission file in the correct format. Each data entry contained:\nid: An identifier for each sentence. FalseSent: The nonsensical sentence. OptionA, OptionB, OptionC: Potential explanations. answer: The correct answer among the options. My Experience and Approach # Participating in this competition was both a challenging and enlightening experience. I utilized several techniques to enhance the model\u0026rsquo;s ability to discern common sense. Here‚Äôs a brief overview of my approach:\nData Preprocessing: Cleaning and preparing the dataset for efficient model training. Model Selection: Leveraging transformer-based models such as BERT, known for their superior natural language understanding capabilities. Fine-tuning: Adapting pre-trained models to the specific task of common sense reasoning using the provided dataset. Evaluation and Optimization: Iteratively evaluating model performance on a validation set and optimizing hyperparameters to improve accuracy. Conclusion # The competition highlighted the ongoing challenges and advancements in integrating common sense into AI systems. By tackling seemingly simple yet fundamentally complex tasks, we push the boundaries of what AI can achieve, moving closer to creating systems that understand and interact with the world more naturally.\nFor more details about the competition, you can visit the Kaggle competition page.\n","date":"15 February 2022","externalUrl":null,"permalink":"/posts/common-sense-in-llm/","section":"Posts","summary":"Enhancing Common Sense in Large Language Models: Insights from a Kaggle Competition # Endowing AI with common sense, the intuitive understanding of everyday situations, remains a significant hurdle.","title":"Enhancing Common Sense in Large Language Models: Insights from a Kaggle Competition","type":"posts"},{"content":"","date":"15 February 2022","externalUrl":null,"permalink":"/tags/llms/","section":"Tags","summary":"","title":"LLMs","type":"tags"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]